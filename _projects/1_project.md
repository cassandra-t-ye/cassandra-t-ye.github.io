


<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Starlight Denoising</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

        <!--FACEBOOK-->
    <meta property="og:image" content="https://kristinamonakhova.com/starlight_denoising/img/square.png">
    <meta property="og:image:type" content="image/jpeg">
    <meta property="og:image:width" content="1024">
    <meta property="og:image:height" content="512">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://kristinamonakhova.com/starlight_denoising"/>
    <meta property="og:title" content="Uncertainty-Driven-Adaptive-Acquisition" />
    <meta property="og:description" content="Project page for Learned, Uncertainty-Driven Adaptive Acquisition for Photon-Efficient Multiphoton Microscop" />

        <!--TWITTER-->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Starlight Denoising" />
    <meta name="twitter:description" content="Project page for Dancing under the stars: video denoising in starlight." />
    <meta name="twitter:image" content="https://kristinamonakhova.com/starlight_denoising/img/square.png" />


<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
  <link rel="icon" type="image/png" href="img/square.png">
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">


    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-20 text-center">
                Learned, Uncertainty-Driven Adaptive Acquisition <br>
                 for Photon-Efficient Multiphoton Microscopy</br>
                <small>
         
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://kristinamonakhova.com/">
                          Cassandra Tong Ye
                        </a>
                        </br>MIT
                    </li>
                    <li>
                        <a href=""></a>
                          Jiashu Han
                        </a>
											</br>Columbia University
                    </li>
                    <li>
                        <a href=""></a>
                            Kunzan Liu
                        </a>
                        </br>MIT
                    </li>
                    <li>
                        <a href="https://people.eecs.berkeley.edu/~angelopoulos/">
                          Anastasios Angelopoulos
                        </a>
											</br>UC Berkeley
                    </li>
                    <li>
                        <a href="https://lgglab.mit.edu/">
                          Linda Griffith
                        </a>
											</br>MIT
                    </li>
                    <li>
                        <a href="http://kristinamonakhova.com/">
                          Kristina Monakhova
                        </a>
											</br>MIT
                    </li>
                    <li>
                        <a href="https://sixianyou.mit.edu/">
                          Sixian You
                        </a>
											</br>MIT
                    </li>

                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/abs/2310.16102">
                            <image src="https://github.com/cassandra-t-ye/Learned_Uncertainty_Quantification/blob/gh-pages/hosted_imgs/paper_front_page.png" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/cassandra-t-ye/Learned_Uncertainty_Quantification/">
                            <image src="https://github.com/cassandra-t-ye/Learned_Uncertainty_Quantification/blob/gh-pages/hosted_imgs/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <!-- <! --<image src="img/header.png" class="img-responsive" alt="overview"><br>  -->
                <p class="text-justify">
                    Multiphoton microscopy (MPM) is a powerful imaging tool that has been a critical enabler for live tissue imaging. However, since most multiphoton microscopy platforms rely on point scanning, there is an inherent trade-off between acquisition time, field of view (FOV), phototoxicity, and image quality, often resulting in noisy measurements when fast, large FOV, and/or gentle imaging is needed. Deep learning could be used to denoise multiphoton microscopy measurements, but these algorithms can be prone to hallucination, which can be disastrous for medical and scientific applications. We propose a method to simultaneously denoise and predict pixel-wise uncertainty for multiphoton imaging measurements, improving algorithm trustworthiness and providing statistical guarantees for the deep learning predictions. Furthermore, we propose to leverage this learned, pixel-wise uncertainty to drive an adaptive acquisition technique that rescans only the most uncertain regions of a sample. We demonstrate our method on experimental noisy MPM measurements of human endometrium tissues, showing that we can maintain fine features and outperform other denoising methods while predicting uncertainty at each pixel. Finally, with our adaptive acquisition technique, we demonstrate a 120X reduction in acquisition time and total light dose while successfully recovering fine features in the sample. We are the first to demonstrate distribution-free uncertainty quantification for a denoising task with real experimental data and the first to propose adaptive acquisition based on reconstruction uncertainty. 
                </p>
            </div>
        </div>

        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Overview Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://www.youtube.com/embed/eFvQs2j9RMw" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
                <p class="text-justify">
                For a longer, in-depth video (60min), see <a = href="https://drive.google.com/file/d/15X3-S-OjsFS_O67qBtde2EPdQNhEoNQB/view?usp=sharing">here</a>.</p>

            </div>
          </div> -->


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Multiphoton Microscopy
                </h3>
                <image src="https://github.com/cassandra-t-ye/Learned_Uncertainty_Quantification/blob/gh-pages/hosted_imgs/multiphoton.png" />
								<p class="text-justify">
                    Here we show our denoised 5-10fps videos taken at submillilux light levels with no external illumination.</p>

            </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Comparison against other methods
                </h3>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/media18.mov" type="video/mp4" />
                </video>
                <p class="text-justify">
                    Our method produces good temporal consistency and minimal artifacts at the lowest light levels.</p>

            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    <a id="dataset">Dancing under the stars Dataset</a>
                </h3>
                <p class="text-justify">
                    We provide a dataset of submillilux images as well as a dataset
                    of calibration images (paired). All images are available either in RAW
                  format (.DNG) or as a preloaded .mat file. </p>

                    <h4> Submillilux videos</h4>
                    <video id="v0" width="100%" autoplay loop muted controls>
                      <source src="img/dataset.mp4" type="video/mp4" />
                    </video>
                    <p class="text-justify">
                    We provide 42 unpaired raw noisy video clips taken at 5-10fps. These video clips
                    vary in length, totalling over 35 minutes of content. All videos were taken on
                     a clear, moonless night with no external illumination and each clip contains significant
                  motion (e.g. dancing, volleyball, flags waving, etc.), serving as a challenging
                  test for video denoising algorithms. </p>
                    <ul>
                      <li>Submillilux Dataset (92 GB): <a href = "https://drive.google.com/drive/folders/1KFXAoJ8Hbtfb7g-WPex-rt8dJsbqZ7sk?usp=sharing">
                        [link]</a></li>
                    </ul></p>

                  <h4> Paired calibration images</h4>
                  <p class="text-justify">
                  We provide several bursts of paired images for the purpose of
                noise model training. </p>
                <p class="text-justify">
                  <ul>
                    <li>Natural scenes (38.2 GB): <a href = "https://drive.google.com/drive/folders/1hgco5RqMgdXXCmDpbyIccWshkOEPQdEH?usp=sharing">
                      [link]</a></li>
                    <li>Grayscale paired (10.5 GB): <a href = "https://drive.google.com/drive/folders/1a6Zsu5OKuukpxRn65N7wsiH5Q_zRr84T?usp=sharing">
                    [link]</a></li>
                  </ul></p>

                  <h4> Unpaired clean RGB+NIR videos</h4>
                  <p class="text-justify">
                  Since we use a RGB+NIR camera instead of an RGB cameras, we also
                provide a dataset of clean (noiseless) videos from our camera.</p>
                <p class="text-justify">
                  <ul>
                    <li>Unpaired clean dataset: <a href = "https://drive.google.com/drive/folders/11eyy818m2KE3N3uzQ262Qvqz0EBh3ytU?usp=sharing">
                      [link]</a></li>
                  </ul></p>



            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@InProceedings{Monakhova_2022_CVPR,
    author    = {Monakhova, Kristina and Richter, Stephan R. and Waller, Laura and Koltun, Vladlen},
    title     = {Dancing Under the Stars: Video Denoising in Starlight},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {16241-16251}
  }
</textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <p class="text-justify">
                  Supplemental materials for the paper can be found
                  <a href="img/CVPR_2022_Starlight_Denoising_Supp.pdf">here</a>. <br>
                The website template was borrowed from <a href="https://bmild.github.io/fourfeat/">Ben Mildenhall</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
