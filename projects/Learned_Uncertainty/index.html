<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Learned, Uncertainty-driven Adaptive Acquisition for Photon-Efficient Multiphoton Microscopy | Cassandra T. Ye</title> <meta name="author" content="Cassandra T. Ye"> <meta name="description" content="Cassandra T. Ye's personal website "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://cassandra-t-ye.github.io/projects/Learned_Uncertainty/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Cassandra T. Ye</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Learned, Uncertainty-driven Adaptive Acquisition for Photon-Efficient Multiphoton Microscopy</h1> <p class="post-description"></p> </header> <article> <p><a href="https://kristinamonakhova.com/" rel="external nofollow noopener" target="_blank">Cassandra Tong Ye</a>, Jiashu Han, <a href="https://liukunzan.github.io/" rel="external nofollow noopener" target="_blank">Kunzan Liu</a>, <a href="https://people.eecs.berkeley.edu/~angelopoulos/" rel="external nofollow noopener" target="_blank">Anastasios Angelopoulos</a>, <a href="https://lgglab.mit.edu/" rel="external nofollow noopener" target="_blank">Linda Griffith</a>, <a href="http://kristinamonakhova.com/" rel="external nofollow noopener" target="_blank">Kristina Monakhova</a>, <a href="https://sixianyou.mit.edu/" rel="external nofollow noopener" target="_blank">Sixian You</a></p> <div style="text-align: center;"> <div style="display: inline-block;"> <a href="https://github.com/cassandra-t-ye/Learned_Uncertainty_Quantification" style="display: block; text-align: center;" rel="external nofollow noopener" target="_blank"> <img src="/assets/img/proj_1/github.png" alt="Github Repo" style="width: 70px; height: auto; margin-right: 20px; margin: 0 auto;"> </a> <div class="caption" style="text-align: center;">Github Repo</div> </div> <div style="display: inline-block;"> <a href="https://arxiv.org/abs/2310.16102" style="display: block; text-align: center;" rel="external nofollow noopener" target="_blank"> <img src="/assets/img/proj_1/paper_front_page.png" alt="Arxiv Paper" style="width: 70px; height: auto; margin-left: 20px; margin: 0 auto;"> </a> <div class="caption" style="text-align: center;">Arxiv Paper</div> </div> </div> <div class="section"> <b style="font-size: 24px;">Abstract</b> <div class="row"> <div class="col-md-12" style="text-align: center;"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/proj_1/teaser.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/proj_1/teaser.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/proj_1/teaser.gif-1400.webp"></source> <img src="/assets/img/proj_1/teaser.gif" class="img-fluid " width="auto" height="auto" title="Multiphoton Microscopy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-md-12"> Scanning microscopy systems, such as confocal and multiphoton microscopy, are powerful imaging tools for probing deep into biological tissue. However, scanning systems have an inherent trade-off between acquisition time, field of view, phototoxicity, and image quality, often resulting in noisy measurements when fast, large field of view, and/or gentle imaging is needed. Deep learning could be used to denoise noisy microscopy measurements, but these algorithms can be prone to hallucination, which can be disastrous for medical and scientific applications. We propose a method to simultaneously denoise and predict pixel-wise uncertainty for scanning microscopy systems, improving algorithm trustworthiness and providing statistical guarantees for deep learning predictions. Furthermore, we propose to leverage this learned, pixel-wise uncertainty to drive an adaptive acquisition technique that rescans only the most uncertain regions of a sample, saving time and reducing the total light dose to the sample. We demonstrate our method on experimental confocal and multiphoton microscopy systems, showing that our uncertainty maps can pinpoint hallucinations in the deep learned predictions. Finally, with our adaptive acquisition technique, we demonstrate up to 16 times reduction in acquisition time and total light dose while successfully recovering fine features in the sample and reducing hallucinations. We are the first to demonstrate distribution-free uncertainty quantification for a denoising task with real experimental data and the first to propose adaptive acquisition based on reconstruction uncertainty. </div> </div> </div> <div class="section" style="margin-top: 20px;"> <b style="font-size: 24px;">Intro to Scanning</b> <div class="row"> <div class="col-md-6"> Many popular microscopy modalities leverage scanning to probe deep into biological tissues; they focus light to a small region of a sample and collect light only from that region. By scanning light to different regions of the sample, they build up three-dimensional images of the sample often one point at a time. Scanning confocal microscopes have been widely adopted for medical and scientific applications due to their ability to recover three-dimensional structures by optical sectioning. Two-photon and multiphoton microscopy leverage non-linear excitation to probe even deeper into thick, scattering tissue. These systems are often used by neuroscientists to measure calcium dynamics in deep scattering mouse brains, as well as to characterize multicellular dynamics in immunology and cancer studies. In addition, label-free multiphoton microscopy enables minimally invasive imaging of biological structures in living and unlabeled biosystems, such as collagen fibers, immune cells, endothelial cells, and extracellular vesicles, through second harmonic generation (SHG), third harmonic generation (THG), and two-photon and three-photon autofluorescence (2PAF, 3PAF). This has become an increasingly popular tool for tissue and cell microscopy in neuroscience, immunology, and cancer research. To provide a minimally perturbative window into the tissue architecture and cell dynamics of intact biosystems, the next advances in scanning microscopy require deeper, faster, and gentler imaging of thick and living samples. For scanning microscopy systems, there is an inherent trade-off between acquisition time, field of view, phototoxicity, and image quality, often resulting in noisy measurements when fast, large field of view, deep, and/or gentle imaging is needed. Noisy images can be challenging to interpret, and fine structures within the images can be obscured by noise. </div> <div class="col-md-6"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/proj_1/mpm-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/proj_1/mpm-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/proj_1/mpm-1400.webp"></source> <img src="/assets/img/proj_1/mpm.png" class="img-fluid " width="auto" height="auto" title="Multiphoton Microscopy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption" style="text-align: left;"> Multiphoton microscopy (MPM), a type of scanning microscopy, is a powerful imaging tool that has been a critical enabler for live tissue imaging. </div> </div> </div> </div> <div class="section" style="margin-top: 20px;"> <b style="font-size: 24px;">Proposed Method</b> <div class="row"> <div class="col-sm mt-3 mt-md-0" style="text-align: center;"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/proj_1/fig_1_gif.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/proj_1/fig_1_gif.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/proj_1/fig_1_gif.gif-1400.webp"></source> <img src="/assets/img/proj_1/fig_1_gif.gif" class="img-fluid " width="700px" height="auto" title="Fig. 1 Summary" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption" style="text-align: left;"> <b>Uncertainty-based Adaptive Imaging</b>: A noisy measurement is acquired with a scanning microscopye and passed into a deep learning model that predicts a denoised image and its associated pixel-wise uncertainty. Subsequently, the top N uncertain pixels are selected for a rescan, obtaining more measurements at only the uncertain regions. As more adaptive measurements are taken, the deep learning model predicts a denoised image with lower uncertainty. Scan duration and power are minimized, limiting sample damage while maintaining high confidence in the model prediction. </div> </div> <div class="col-md-12"> Deep learning (DL) based methods have shown exciting results for denoising extremely noisy images in microscopy, however, they still produce hallucinations. To counter this uncertainty quantification techniques can help catch model hallucinations and improve the robustness of deep learning methods. We demonstrate distribution-free uncertainty quantification for denoising and <b>propose an adaptive microscopy imaging pipeline</b> informed by uncertainty quantification. This pipeline leverages the learned uncertainty to drive adaptive acquisition: we capture more measurements of our sample only at the most uncertain regions rather than rescanning the whole sample. </div> </div> </div> <div class="section" style="margin-top: 20px;"> <b style="font-size: 24px;">Multi-Image Denoising and Uncertainty Quantification Results</b> <div class="row"> <div class="col-md-12"> We evaluated our denoising and uncertainty prediction on an experimental dataset of confocal and two-photon measurements (FMD dataset) as well as a custom multiphoton dataset (MPM dataset). First, we test our denoiser’s performance as a function of the number of noisy measurements. To do this, we vary the input to the network, feeding in 1-20 unique, non-moving, noisy measurements. Each measurement has a different instance of noise, so intuitively, with more measurements, the denoising prediction should improve. In the image below, we show the predicted denoised images and uncertainty maps for samples from the FMD dataset. Here, we can see that as the number of measurements increases, the network’s predicted uncertainty decreases, and concurrently, the denoised predictions become sharper and closer to the ground truth. In the zoomed in portion of the image, we demonstrate a hallucination that was observed in the first denoised iteration (indicated by high uncertainty), which is resolved by the tenth denoised iteration. </div> <div class="col-sm mt-3 mt-md-0" style="text-align: center;"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/proj_1/results_2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/proj_1/results_2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/proj_1/results_2-1400.webp"></source> <img src="/assets/img/proj_1/results_2.png" class="img-fluid " width="auto" height="auto" title="Fig. 2 Denoising Results for FMD Samples" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </div> <div class="section" style="margin-top: 20px;"> <b style="font-size: 24px;">Uncertainty informed Adaptive Acquisition</b> <div class="row"> <div class="col-sm mt-3 mt-md-0" style="text-align: center;"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/proj_1/results_3-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/proj_1/results_3-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/proj_1/results_3-1400.webp"></source> <img src="/assets/img/proj_1/results_3.png" class="img-fluid" width="auto" height="auto" title="Fig. 3 UQ" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption" style="text-align: left;"> <b>Adaptive Acquisition of two-photon images:</b>: e compare three different color channels from a two-photon sample from the FMD dataset. After single-image denoising, we threshold the uncertainty to obtain an adaptive mask (center). Each channel has a different percentage of rescanned pixels (red text), which leads to a total light dosage savings of x2.6, x2.7, x5.6, respectively. . </div> </div> <div class="col-md-12"> Does uncertainty-guided adaptive acquisition retain image quality, while decreasing the total number of pixels needed and increasing the light-dosage savings? We investigated the effects of different adaptive percentages on different two-photon samples. In this experiment, we show the adaptive mask slowly changing through iterations- with earlier iterations needing more pixels and later iterations exclusively segmenting areas of high signal to adaptively acquire. After the 20th iteration, zoomed-in samples of the adaptively acquired and denoised image demonstrate that it maintains the same level of details for sample features, while providing a significant improvement in acquisition parameters. In the figure presented, we show an improvement between 2.6 and 5.6 times in light dosage while retaining image quality. </div> </div> </div> <div class="section" style="margin-top: 20px;"> <b style="font-size: 24px;">Adaptive Acquisition of samples can catch hallucinations</b> <div class="row"> <div class="col-sm mt-3 mt-md-0" style="text-align: center;"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/proj_1/results_4-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/proj_1/results_4-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/proj_1/results_4-1400.webp"></source> <img src="/assets/img/proj_1/results_4.png" class="img-fluid " width="auto" height="auto" title="Fig. 4 Rescan Percentages" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-md-12"> We also show that our adaptive method is still capable of locating and resolving model hallucination in scanning microscopy images. In the figure presented, we demonstrate that adaptively rescanning can resolve hallucinations in both confocal and experimental MPM samples at different rescanning percentages. In the MPM sample, rescanning at 80% allows for a 1.25 times savings in light-dose, while in the confocal sample, rescanning at 6% allows for a 16.7 savings in light-dose. It is important to note that optimal rescanning percentages are highly dependent on the sample itself. As shown, a sparse sample will need a lower percentage of pixels rescanned, while a dense sample will need a much higher rescanning percentage. </div> <div class="col-sm mt-3 mt-md-0" style="text-align: center;"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/proj_1/results_5-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/proj_1/results_5-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/proj_1/results_5-1400.webp"></source> <img src="/assets/img/proj_1/results_5.png" class="img-fluid " width="auto" height="auto" title="Fig. 5 Visual UQ Rescan" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </div> <div class="section" style="margin-top: 20px;"> <b style="font-size: 24px;">Conclusion</b> <p> We presented a method to utilize learned, distribution-free uncertainty quantification for multi-image denoising and proposed an adaptive acquisition technique based on the learned uncertainty. In this paper, we demonstrate that our method of uncertainty-driven adaptive acquisition works on experimental confocal, two-photon, and multiphoton microscopy systems, showing a potential 1-16 times decrease in total scanning time and light dose while successfully recovering fine structures. Our method can be adapted for different forms of scanning microscopy without explicit retraining or fine-tuning. Our network trained on FMD data can be used on different data after performing the conformal calibration step using a small calibration dataset. This is one of the advantages of conformal calibration - uncertainty predictions will still hold after calibrating for a different dataset without explicit retraining. All of the statistical guarantees will still hold; however, the size of the uncertainty bounds may increase since the network is not optimized for the data or imaging modality. We discuss this further in Suppl. Section 7. These speed and total light dose improvements are significant and demonstrate an important step towards faster and gentler scanning microscopy, which will enable the imaging of a new class of interesting samples and lead to new scientific insights and advances. </p> <p> Furthermore, we demonstrate how deep learning methods for microscopy can be designed to be trustworthy by building in uncertainty quantification to provide error bars for each prediction. Our method successfully identified model hallucinations, which were reduced by taking more measurements or adaptively rescanning the most uncertain regions of the sample. Our method of quantifying uncertainty provides guarantees for the reliability of the prediction. Uncertainty quantification should become standard practice when using deep-learning techniques for scientific and medical imaging to reduce hallucinations and build confidence in image predictions. We believe that the distribution-free learned uncertainty quantification presented here is an attractive path toward this due to its ease of use, fast computational time, and statistical guarantees. </p> </div> <div class="row" style="margin-top: 20px;"> <div class="col-md-12"> <b style="font-size: 24px;">Bibtex Citation</b> <div class="form-group col-md-12"> <textarea id="bibtex" class="form-control" readonly>
            @article{ye2023learned,
                title       = {Learned, Uncertainty-driven Adaptive Acquisition for Photon-Efficient Multiphoton Microscopy},
                author      = {Ye, Cassandra Tong and Han, Jiashu and Liu, Kunzan and Angelopoulos, Anastasios and Griffith, Linda and Monakhova, Kristina and You, Sixian},
                journal     = {arXiv preprint arXiv:2310.16102},
                year        = {2023}
            }
            </textarea> </div> </div> </div> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="ye2023learned" class="col-sm-8"> <div class="title">Learned, Uncertainty-driven Adaptive Acquisition for Photon-Efficient Multiphoton Microscopy</div> <div class="author"> Cassandra Tong Ye, Jiashu Han, Kunzan Liu, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Anastasios Angelopoulos, Linda Griffith, Kristina Monakhova, Sixian You' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>arXiv preprint arXiv:2310.16102</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Cassandra T. Ye. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: February 24, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-P2XMV2NHP4"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-P2XMV2NHP4");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>